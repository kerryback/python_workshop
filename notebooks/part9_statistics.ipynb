{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-image: url('https://www.dropbox.com/scl/fi/wdrnuojbnjx6lgfekrx85/mcnair.jpg?rlkey=wcbaw5au7vh5vt1g5d5x7fw8f&dl=1'); background-size: cover; background-position: center; height: 300px; display: flex; align-items: center; justify-content: center; color: white; text-shadow: 2px 2px 4px rgba(0,0,0,0.7); margin-bottom: 20px; position: relative;\">\n",
    "  <h1 style=\"text-align: center; font-size: 2.5em; margin: 0;\">JGSB Python Workshop <br> Part 9: Statistics</h1>\n",
    "  <div style=\"position: absolute; bottom: 10px; left: 15px; font-size: 0.9em; color: white; text-shadow: 2px 2px 4px rgba(0,0,0,0.7);\">\n",
    "    Authored by Kerry Back\n",
    "  </div>\n",
    "  <div style=\"position: absolute; bottom: 10px; right: 15px; text-align: right; font-size: 0.9em; color: white; text-shadow: 2px 2px 4px rgba(0,0,0,0.7);\">\n",
    "    Rice University, 9/6/2025\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# t Test for a Population Mean\n\nA one-sample t-test determines whether a sample mean differs significantly from a hypothesized population mean. This is commonly used in business to test whether actual performance meets targets or expectations.\n\n**Key Concepts:**\n- **Null Hypothesis (H₀):** The sample mean equals the hypothesized population mean\n- **Alternative Hypothesis (H₁):** The sample mean differs from the hypothesized population mean\n- **t-statistic:** Measures how far the sample mean is from the hypothesized mean in standard error units\n- **p-value:** Probability of observing the test statistic if the null hypothesis is true\n\n**When to Use:**\n- Testing if average sales meet targets\n- Checking if customer satisfaction scores differ from industry standards\n- Validating if production times match specifications\n\n## Example: Testing Average Order Value\n\nLet's test whether our online store's average order value differs from the industry standard of $75.",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# t Test for a Difference of Means with Paired Treatment\n\nA paired t-test compares two related measurements on the same subjects, testing whether the mean difference between paired observations is significantly different from zero. This is powerful for before-and-after comparisons in business.\n\n**Key Concepts:**\n- **Paired Data:** Two measurements on the same experimental unit (person, store, product, etc.)\n- **Null Hypothesis (H₀):** The mean difference between pairs equals zero\n- **Alternative Hypothesis (H₁):** The mean difference between pairs does not equal zero\n- **Advantages:** Controls for individual differences, increasing statistical power\n\n**Business Applications:**\n- Before/after training program effectiveness\n- Pre/post marketing campaign performance\n- Website A/B testing with user sessions\n- Sales performance before/after system implementation\n\n## Example: Email Marketing Campaign Effectiveness\n\nLet's test whether a new email marketing strategy increases weekly sales compared to the previous strategy using the same 20 stores.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# t Test of a Difference of Means with Independent Samples\n\nAn independent samples t-test compares the means of two unrelated groups to determine if they differ significantly. This is essential for comparing different treatments, groups, or conditions in business research.\n\n**Key Concepts:**\n- **Independent Groups:** Separate, unrelated samples (different people, stores, regions, etc.)\n- **Null Hypothesis (H₀):** The two population means are equal\n- **Alternative Hypothesis (H₁):** The two population means are different\n- **Assumptions:** Normal distribution, independent observations, similar variances\n\n**Business Applications:**\n- Comparing performance between departments\n- Testing difference in customer satisfaction across regions\n- Evaluating effectiveness of different marketing strategies\n- Analyzing sales differences between product versions\n\n## Example: Regional Sales Performance Comparison\n\nLet's compare average monthly sales between the East and West regions to determine if there's a significant difference in performance.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Linear Regression: The Formula Method\n\nLinear regression using the formula method (Patsy formulas) provides an intuitive, R-like syntax for specifying regression models. This approach is excellent for business analysts who want readable, flexible model specifications.\n\n**Key Concepts:**\n- **Formula Syntax:** Uses string formulas like `'y ~ x1 + x2'` to specify relationships\n- **Automatic Handling:** Categorical variables, interactions, and transformations\n- **Business Interpretation:** Coefficients represent the change in Y for a one-unit change in X\n- **R-squared:** Proportion of variance in the dependent variable explained by the model\n\n**Formula Syntax Examples:**\n- `'sales ~ advertising'` - Simple linear regression\n- `'sales ~ advertising + price'` - Multiple regression\n- `'sales ~ advertising * region'` - Interaction terms\n- `'sales ~ np.log(advertising)'` - Transformations\n\n## Example: Predicting Sales from Advertising Spend\n\nLet's build a model to predict monthly sales based on advertising expenditure and store size.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Linear Regression: The Matrix Method\n\nThe matrix method provides direct access to the mathematical foundation of linear regression using matrix operations. This approach offers maximum flexibility and is essential for understanding custom model implementations and advanced techniques.\n\n**Key Concepts:**\n- **Matrix Form:** Y = Xβ + ε, where Y is dependent variable, X is design matrix, β is coefficients\n- **Normal Equation:** β = (X'X)⁻¹X'Y solves for optimal coefficients\n- **Design Matrix:** X includes intercept column and all independent variables\n- **Direct Control:** Full access to intermediate calculations and custom modifications\n\n**When to Use Matrix Method:**\n- Custom model specifications not available in formula syntax\n- Understanding mathematical foundations\n- Building specialized regression techniques\n- Performance-critical applications\n- Research and advanced analytics\n\n## Example: Portfolio Return Analysis\n\nLet's predict portfolio returns using the matrix method with multiple risk factors.",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Exercise: Custom Regression Implementation\n\nBuild a custom weighted regression model where observations have different importance weights. This technique is valuable when some data points are more reliable or representative than others.\n\n**Your Task:**\n1. Generate sample data:\n   ```python\n   np.random.seed(202)\n   x1 = np.random.uniform(10, 50, 60)\n   x2 = np.random.uniform(5, 20, 60)\n   weights = np.random.uniform(0.5, 2.0, 60)  # Observation weights\n   y = 100 + 3*x1 + 2*x2 + np.random.normal(0, 8, 60)\n   ```\n\n2. Implement weighted least squares using matrix operations:\n   - Create design matrix X with intercept, x1, and x2\n   - Create weight matrix W = diag(weights)\n   - Use weighted normal equation: β = (X'WX)⁻¹X'Wy\n\n3. Compare results with unweighted regression using `sm.OLS()`\n4. Use `sm.WLS()` to verify your manual calculation\n5. Interpret the differences between weighted and unweighted models",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Generate financial data for matrix regression\nnp.random.seed(42)\nn_periods = 200\n\n# Risk factors (independent variables)\nmarket_return = np.random.normal(0.08, 0.15, n_periods)    # Market factor\nsize_factor = np.random.normal(0.02, 0.10, n_periods)      # Size factor  \nvalue_factor = np.random.normal(0.01, 0.08, n_periods)     # Value factor\n\n# Portfolio return (dependent variable) - based on factor model\nportfolio_return = (0.03 +                                 # Alpha\n                   0.8 * market_return +                   # Market beta\n                   0.3 * size_factor +                     # Size loading\n                   -0.1 * value_factor +                   # Value loading\n                   np.random.normal(0, 0.05, n_periods))   # Idiosyncratic risk\n\n# Method 1: Using statsmodels with matrix approach\n# Create design matrix X (includes intercept)\nX = np.column_stack([\n    np.ones(n_periods),      # Intercept column\n    market_return,           # Market factor\n    size_factor,            # Size factor  \n    value_factor            # Value factor\n])\n\ny = portfolio_return\n\n# Fit model using matrix method\nmatrix_model = sm.OLS(y, X).fit()\n\nprint(\"MATRIX METHOD RESULTS:\")\nprint(\"=\"*50)\nprint(f\"Coefficients:\")\nfactor_names = ['Intercept (Alpha)', 'Market Beta', 'Size Loading', 'Value Loading']\nfor i, (name, coef) in enumerate(zip(factor_names, matrix_model.params)):\n    print(f\"{name:20s}: {coef:8.4f}\")\n\nprint(f\"\\nModel Statistics:\")\nprint(f\"R-squared: {matrix_model.rsquared:.4f}\")\nprint(f\"Adjusted R-squared: {matrix_model.rsquared_adj:.4f}\")\nprint(f\"F-statistic: {matrix_model.fvalue:.4f}\")\nprint(f\"Prob (F-statistic): {matrix_model.f_pvalue:.4f}\")\n\n# Method 2: Manual calculation using normal equation\nprint(\"\\n\" + \"=\"*50)\nprint(\"MANUAL MATRIX CALCULATION:\")\nprint(\"=\"*50)\n\n# Calculate coefficients manually: β = (X'X)^(-1)X'Y\nXtX = X.T @ X                    # X transpose times X\nXtX_inv = np.linalg.inv(XtX)     # Inverse of X'X\nXty = X.T @ y                    # X transpose times y\nbeta_manual = XtX_inv @ Xty      # Final coefficients\n\nprint(\"Manual coefficients (should match statsmodels):\")\nfor i, (name, coef) in enumerate(zip(factor_names, beta_manual)):\n    print(f\"{name:20s}: {coef:8.4f}\")\n\n# Calculate fitted values and residuals\ny_fitted = X @ beta_manual\nresiduals = y - y_fitted\nrss = np.sum(residuals**2)       # Residual sum of squares\ntss = np.sum((y - np.mean(y))**2) # Total sum of squares\nr_squared_manual = 1 - (rss / tss)\n\nprint(f\"\\nManual R-squared: {r_squared_manual:.4f}\")\n\n# Show the mathematical relationship\nprint(f\"\\nPortfolio Return Model:\")\nprint(f\"Return = {beta_manual[0]:.4f} + {beta_manual[1]:.4f}*Market + {beta_manual[2]:.4f}*Size + {beta_manual[3]:.4f}*Value\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Generate business data for regression analysis\nnp.random.seed(42)\nn_stores = 100\n\n# Independent variables\nadvertising = np.random.uniform(5000, 25000, n_stores)  # Monthly ad spend\nstore_size = np.random.uniform(1000, 5000, n_stores)    # Square footage\nregion = np.random.choice(['North', 'South', 'East', 'West'], n_stores)\n\n# Dependent variable with realistic business relationship\n# Sales = base + advertising effect + store size effect + region effect + noise\nsales = (50000 + \n         1.2 * advertising +           # $1.20 return per $1 ad spend\n         8 * store_size +              # $8 per sq ft\n         np.where(region == 'North', 5000,\n         np.where(region == 'South', -2000, \n         np.where(region == 'East', 3000, 0))) +  # Regional differences\n         np.random.normal(0, 10000, n_stores))    # Random variation\n\n# Create DataFrame\nbusiness_data = pd.DataFrame({\n    'sales': sales,\n    'advertising': advertising,\n    'store_size': store_size,\n    'region': region\n})\n\nprint(\"Business Data Summary:\")\nprint(business_data.describe().round(2))\nprint(f\"\\nRegion distribution:\")\nprint(business_data['region'].value_counts())\n\n# Fit regression model using formula method\nimport statsmodels.formula.api as smf\n\n# Simple regression\nsimple_model = smf.ols('sales ~ advertising', data=business_data).fit()\nprint(\"\\n\" + \"=\"*50)\nprint(\"SIMPLE REGRESSION: Sales ~ Advertising\")\nprint(\"=\"*50)\nprint(simple_model.summary().tables[1])\nprint(f\"R-squared: {simple_model.rsquared:.4f}\")\n\n# Multiple regression\nmultiple_model = smf.ols('sales ~ advertising + store_size', data=business_data).fit()\nprint(\"\\n\" + \"=\"*50)\nprint(\"MULTIPLE REGRESSION: Sales ~ Advertising + Store Size\")\nprint(\"=\"*50)\nprint(multiple_model.summary().tables[1])\nprint(f\"R-squared: {multiple_model.rsquared:.4f}\")\n\n# Model with categorical variable\nfull_model = smf.ols('sales ~ advertising + store_size + region', data=business_data).fit()\nprint(\"\\n\" + \"=\"*50)\nprint(\"FULL MODEL: Sales ~ Advertising + Store Size + Region\")\nprint(\"=\"*50)\nprint(full_model.summary().tables[1])\nprint(f\"R-squared: {full_model.rsquared:.4f}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Generate independent samples for two regions\nnp.random.seed(42)\n\n# East region sales (30 stores) - higher performing region\neast_sales = np.random.normal(85000, 15000, 30)\n\n# West region sales (25 stores) - lower performing region  \nwest_sales = np.random.normal(78000, 12000, 25)\n\n# Create combined dataset for analysis\nregional_data = pd.DataFrame({\n    'Sales': np.concatenate([east_sales, west_sales]),\n    'Region': ['East'] * 30 + ['West'] * 25\n})\n\nprint(\"Regional Sales Summary:\")\nsummary_stats = regional_data.groupby('Region')['Sales'].agg(['count', 'mean', 'std']).round(2)\nprint(summary_stats)\n\n# Check for equal variances (Levene's test)\nfrom scipy.stats import levene\nlevene_stat, levene_p = levene(east_sales, west_sales)\nprint(f\"\\nLevene's test for equal variances:\")\nprint(f\"Test statistic: {levene_stat:.4f}, p-value: {levene_p:.4f}\")\n\nequal_var = levene_p > 0.05\nprint(f\"Equal variances assumption: {'Met' if equal_var else 'Violated'}\")\n\n# Perform independent samples t-test\nt_stat, p_value = stats.ttest_ind(east_sales, west_sales, equal_var=equal_var)\n\nprint(f\"\\nIndependent Samples t-Test:\")\nprint(f\"t-statistic: {t_stat:.4f}\")\nprint(f\"p-value: {p_value:.4f}\")\n\n# Calculate effect size (Cohen's d)\npooled_std = np.sqrt(((len(east_sales) - 1) * np.var(east_sales, ddof=1) + \n                     (len(west_sales) - 1) * np.var(west_sales, ddof=1)) / \n                     (len(east_sales) + len(west_sales) - 2))\ncohens_d = (np.mean(east_sales) - np.mean(west_sales)) / pooled_std\nprint(f\"Cohen's d (effect size): {cohens_d:.4f}\")\n\n# Interpretation\nalpha = 0.05\nif p_value < alpha:\n    print(f\"\\nConclusion: Reject H₀ (p < {alpha})\")\n    print(\"Significant difference between East and West region sales\")\n    difference = np.mean(east_sales) - np.mean(west_sales)\n    print(f\"East region outperforms West by ${difference:.2f} on average\")\nelse:\n    print(f\"\\nConclusion: Fail to reject H₀ (p ≥ {alpha})\")\n    print(\"No significant difference between regional sales\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Generate paired data for 20 stores\nnp.random.seed(42)\nstore_ids = range(1, 21)\n\n# Sales before new email strategy (baseline)\nsales_before = np.random.normal(5000, 800, 20)\n\n# Sales after new email strategy (generally higher, but with store-specific variation)\n# Each store has its own baseline + random improvement\nstore_effects = np.random.normal(500, 200, 20)  # Average improvement of $500\nsales_after = sales_before + store_effects + np.random.normal(0, 300, 20)\n\n# Create DataFrame for better visualization\nsales_data = pd.DataFrame({\n    'Store_ID': store_ids,\n    'Sales_Before': sales_before,\n    'Sales_After': sales_after,\n    'Difference': sales_after - sales_before\n})\n\nprint(\"Sales Data Summary:\")\nprint(sales_data.describe().round(2))\n\nprint(f\"\\nMean difference: ${sales_data['Difference'].mean():.2f}\")\nprint(f\"Std of differences: ${sales_data['Difference'].std(ddof=1):.2f}\")\n\n# Perform paired t-test\nt_stat, p_value = stats.ttest_rel(sales_after, sales_before)\n\nprint(f\"\\nPaired t-Test Results:\")\nprint(f\"t-statistic: {t_stat:.4f}\")\nprint(f\"p-value: {p_value:.4f}\")\nprint(f\"Degrees of freedom: {len(sales_before) - 1}\")\n\n# Interpretation\nalpha = 0.05\nif p_value < alpha:\n    print(f\"\\nConclusion: Reject H₀ (p < {alpha})\")\n    print(\"The new email strategy significantly increased sales\")\n    print(f\"Average improvement: ${sales_data['Difference'].mean():.2f} per store per week\")\nelse:\n    print(f\"\\nConclusion: Fail to reject H₀ (p ≥ {alpha})\")\n    print(\"No significant difference between email strategies\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# Generate sample data: order values for 50 customers\nnp.random.seed(42)\norder_values = np.random.normal(78.5, 12.3, 50)  # Mean slightly above $75\n\n# Display basic statistics\nprint(\"Sample Statistics:\")\nprint(f\"Sample size: {len(order_values)}\")\nprint(f\"Sample mean: ${np.mean(order_values):.2f}\")\nprint(f\"Sample std: ${np.std(order_values, ddof=1):.2f}\")\nprint(f\"Industry standard: $75.00\")\n\n# Perform one-sample t-test\nhypothesized_mean = 75\nt_stat, p_value = stats.ttest_1samp(order_values, hypothesized_mean)\n\nprint(f\"\\nOne-Sample t-Test Results:\")\nprint(f\"t-statistic: {t_stat:.4f}\")\nprint(f\"p-value: {p_value:.4f}\")\nprint(f\"Degrees of freedom: {len(order_values) - 1}\")\n\n# Interpretation\nalpha = 0.05\nif p_value < alpha:\n    print(f\"\\nConclusion: Reject H₀ (p < {alpha})\")\n    print(\"The average order value significantly differs from $75\")\nelse:\n    print(f\"\\nConclusion: Fail to reject H₀ (p ≥ {alpha})\")\n    print(\"No significant difference from the industry standard of $75\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $t$ Test for a Difference of Means with Paired Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $t$ Test of a Difference of Means with Independent Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression: The Formula Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Linear Regression: The Matrix Method",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}